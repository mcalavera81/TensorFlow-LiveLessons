{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 in TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_image(arr):\n",
    "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(two_d, interpolation='nearest')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.images.shape)\n",
    "print(mnist.test.labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f607dd61278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1\n",
    "print(mnist.train.labels.shape)\n",
    "print(mnist.train.labels[index])\n",
    "gen_image(mnist.train.images[index]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "weight_initializer = tf.contrib.layers.xavier_initializer()\n",
    "display_progress = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer\n",
    "n_input = 784\n",
    "\n",
    "# first convolutional layer\n",
    "n_conv_1 =32\n",
    "k_conv_1 = 3\n",
    "\n",
    "# second convolutional layer\n",
    "n_conv_2 = 64\n",
    "k_conv_2 = 3\n",
    "\n",
    "# max pooling layer\n",
    "pool_size = 2\n",
    "mp_layer_dropout = 0.25\n",
    "\n",
    "# dense layer\n",
    "n_dense = 128\n",
    "dense_layer_dropout = 0.5\n",
    "\n",
    "#output layer\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define placeholder Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense layer with ReLU\n",
    "def dense(x, W, b):\n",
    "    z = tf.add(tf.matmul(x,W),b)\n",
    "    a = tf.nn.relu(z)\n",
    "    return a\n",
    "\n",
    "#conv layer with ReL:\n",
    "def conv2d(x,W,b,stride_length=1):\n",
    "    xW = tf.nn.conv2d(x,W, strides=[1, stride_length,stride_length,1], padding='SAME')\n",
    "    z = tf.nn.bias_add(xW,b)\n",
    "    a = tf.nn.relu(z)\n",
    "    return a\n",
    "\n",
    "#max pooling layer:\n",
    "def maxpooling2d(x,p_size):\n",
    "    return tf.nn.max_pool(x, ksize=(1,p_size,p_size,1),\n",
    "                         strides=[1,p_size,p_size,1],\n",
    "                         padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x, weights, biases, n_in, mp_psize, mp_dropout, dense_dropout):\n",
    "    \n",
    "    # reshape input data\n",
    "    square_dimensions = int(np.sqrt(n_in))\n",
    "    square_x = tf.reshape(x, shape=[-1, square_dimensions, square_dimensions, 1])\n",
    "\n",
    "    #convolutional layers\n",
    "    conv_1 = conv2d(square_x, weights['W_c1'],biases['b_c1'])\n",
    "    conv_2 = conv2d(conv_1, weights['W_c2'],biases['b_c2'])\n",
    "    pool_1 = maxpooling2d(conv_2, mp_psize)\n",
    "    pool_1 = tf.nn.dropout(pool_1, 1-mp_dropout)\n",
    "    \n",
    "    #dense layer\n",
    "    flat = tf.reshape(pool_1, [-1, weights['W_d1'].get_shape().as_list()[0]])\n",
    "    print(weights['W_d1'].get_shape())\n",
    "    print(flat.get_shape())\n",
    "    dense_1 = dense(flat, weights['W_d1'],biases['b_d1'])\n",
    "    dense_1 = tf.nn.dropout(dense_1, 1-dense_dropout)\n",
    "    \n",
    "    \n",
    "    # linear output layer\n",
    "    out_layer_z = tf.add(tf.matmul(dense_1, weights['W_out']),biases['b_out'])\n",
    "    return out_layer_z \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define variable dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_dict = {\n",
    "    'b_c1' : tf.Variable(tf.zeros([n_conv_1])),\n",
    "    'b_c2' : tf.Variable(tf.zeros([n_conv_2])),\n",
    "    'b_d1' : tf.Variable(tf.zeros([n_dense])),\n",
    "    'b_out' : tf.Variable(tf.zeros([n_classes]))\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "full_square_length = np.sqrt(n_input)\n",
    "pooled_square_length = int(full_square_length/pool_size)\n",
    "dense_inputs= pooled_square_length**2 * n_conv_2\n",
    "\n",
    "weights_dict = {\n",
    "    'W_c1' : tf.get_variable('W_c1', [k_conv_1,k_conv_1, 1, n_conv_1], initializer=weight_initializer),\n",
    "    'W_c2' : tf.get_variable('W_c2', [k_conv_2,k_conv_2, n_conv_1, n_conv_2], initializer=weight_initializer),\n",
    "    'W_d1' : tf.get_variable('W_d1', [dense_inputs,n_dense], initializer=weight_initializer),\n",
    "    'W_out': tf.get_variable('W_out', [n_dense, n_classes], initializer=weight_initializer)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12544, 128)\n",
      "(?, 12544)\n"
     ]
    }
   ],
   "source": [
    "predictions = network(x, weights_dict, bias_dict, n_input, pool_size, mp_layer_dropout,\n",
    "                     dense_layer_dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(predictions,1), tf.argmax(y,1))\n",
    "accuracy_pct = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train network in a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for  10  epochs.\n",
      "Step 1 of 429 in epoch 1.\n",
      "Step 41 of 429 in epoch 1.\n",
      "Step 81 of 429 in epoch 1.\n",
      "Step 121 of 429 in epoch 1.\n",
      "Step 161 of 429 in epoch 1.\n",
      "Step 201 of 429 in epoch 1.\n",
      "Step 241 of 429 in epoch 1.\n",
      "Step 281 of 429 in epoch 1.\n",
      "Step 321 of 429 in epoch 1.\n",
      "Step 361 of 429 in epoch 1.\n",
      "Step 401 of 429 in epoch 1.\n",
      "Epoch 001: cost = 0.266, accuracy = 91.86%\n",
      "Step 1 of 429 in epoch 2.\n",
      "Step 41 of 429 in epoch 2.\n",
      "Step 81 of 429 in epoch 2.\n",
      "Step 121 of 429 in epoch 2.\n",
      "Step 161 of 429 in epoch 2.\n",
      "Step 201 of 429 in epoch 2.\n",
      "Step 241 of 429 in epoch 2.\n",
      "Step 281 of 429 in epoch 2.\n",
      "Step 321 of 429 in epoch 2.\n",
      "Step 361 of 429 in epoch 2.\n",
      "Step 401 of 429 in epoch 2.\n",
      "Epoch 002: cost = 0.095, accuracy = 97.19%\n",
      "Step 1 of 429 in epoch 3.\n",
      "Step 41 of 429 in epoch 3.\n",
      "Step 81 of 429 in epoch 3.\n",
      "Step 121 of 429 in epoch 3.\n",
      "Step 161 of 429 in epoch 3.\n",
      "Step 201 of 429 in epoch 3.\n",
      "Step 241 of 429 in epoch 3.\n",
      "Step 281 of 429 in epoch 3.\n",
      "Step 321 of 429 in epoch 3.\n",
      "Step 361 of 429 in epoch 3.\n",
      "Step 401 of 429 in epoch 3.\n",
      "Epoch 003: cost = 0.067, accuracy = 98.01%\n",
      "Step 1 of 429 in epoch 4.\n",
      "Step 41 of 429 in epoch 4.\n",
      "Step 81 of 429 in epoch 4.\n",
      "Step 121 of 429 in epoch 4.\n",
      "Step 161 of 429 in epoch 4.\n",
      "Step 201 of 429 in epoch 4.\n",
      "Step 241 of 429 in epoch 4.\n",
      "Step 281 of 429 in epoch 4.\n",
      "Step 321 of 429 in epoch 4.\n",
      "Step 361 of 429 in epoch 4.\n",
      "Step 401 of 429 in epoch 4.\n",
      "Epoch 004: cost = 0.055, accuracy = 98.30%\n",
      "Step 1 of 429 in epoch 5.\n",
      "Step 41 of 429 in epoch 5.\n",
      "Step 81 of 429 in epoch 5.\n",
      "Step 121 of 429 in epoch 5.\n",
      "Step 161 of 429 in epoch 5.\n",
      "Step 201 of 429 in epoch 5.\n",
      "Step 241 of 429 in epoch 5.\n",
      "Step 281 of 429 in epoch 5.\n",
      "Step 321 of 429 in epoch 5.\n",
      "Step 361 of 429 in epoch 5.\n",
      "Step 401 of 429 in epoch 5.\n",
      "Epoch 005: cost = 0.048, accuracy = 98.51%\n",
      "Step 1 of 429 in epoch 6.\n",
      "Step 41 of 429 in epoch 6.\n",
      "Step 81 of 429 in epoch 6.\n",
      "Step 121 of 429 in epoch 6.\n",
      "Step 161 of 429 in epoch 6.\n",
      "Step 201 of 429 in epoch 6.\n",
      "Step 241 of 429 in epoch 6.\n",
      "Step 281 of 429 in epoch 6.\n",
      "Step 321 of 429 in epoch 6.\n",
      "Step 361 of 429 in epoch 6.\n",
      "Step 401 of 429 in epoch 6.\n",
      "Epoch 006: cost = 0.041, accuracy = 98.71%\n",
      "Step 1 of 429 in epoch 7.\n",
      "Step 41 of 429 in epoch 7.\n",
      "Step 81 of 429 in epoch 7.\n",
      "Step 121 of 429 in epoch 7.\n",
      "Step 161 of 429 in epoch 7.\n",
      "Step 201 of 429 in epoch 7.\n",
      "Step 241 of 429 in epoch 7.\n",
      "Step 281 of 429 in epoch 7.\n",
      "Step 321 of 429 in epoch 7.\n",
      "Step 361 of 429 in epoch 7.\n",
      "Step 401 of 429 in epoch 7.\n",
      "Epoch 007: cost = 0.037, accuracy = 98.86%\n",
      "Step 1 of 429 in epoch 8.\n",
      "Step 41 of 429 in epoch 8.\n",
      "Step 81 of 429 in epoch 8.\n",
      "Step 121 of 429 in epoch 8.\n",
      "Step 161 of 429 in epoch 8.\n",
      "Step 201 of 429 in epoch 8.\n",
      "Step 241 of 429 in epoch 8.\n",
      "Step 281 of 429 in epoch 8.\n",
      "Step 321 of 429 in epoch 8.\n",
      "Step 361 of 429 in epoch 8.\n",
      "Step 401 of 429 in epoch 8.\n",
      "Epoch 008: cost = 0.031, accuracy = 99.00%\n",
      "Step 1 of 429 in epoch 9.\n",
      "Step 41 of 429 in epoch 9.\n",
      "Step 81 of 429 in epoch 9.\n",
      "Step 121 of 429 in epoch 9.\n",
      "Step 161 of 429 in epoch 9.\n",
      "Step 201 of 429 in epoch 9.\n",
      "Step 241 of 429 in epoch 9.\n",
      "Step 281 of 429 in epoch 9.\n",
      "Step 321 of 429 in epoch 9.\n",
      "Step 361 of 429 in epoch 9.\n",
      "Step 401 of 429 in epoch 9.\n",
      "Epoch 009: cost = 0.029, accuracy = 99.06%\n",
      "Step 1 of 429 in epoch 10.\n",
      "Step 41 of 429 in epoch 10.\n",
      "Step 81 of 429 in epoch 10.\n",
      "Step 121 of 429 in epoch 10.\n",
      "Step 161 of 429 in epoch 10.\n",
      "Step 201 of 429 in epoch 10.\n",
      "Step 241 of 429 in epoch 10.\n",
      "Step 281 of 429 in epoch 10.\n",
      "Step 321 of 429 in epoch 10.\n",
      "Step 361 of 429 in epoch 10.\n",
      "Step 401 of 429 in epoch 10.\n",
      "Epoch 010: cost = 0.025, accuracy = 99.20%\n",
      "Training Complete. Testing Model.\n",
      "\n",
      "Test Cost: 0.058\n",
      "Test Accuracy: 98.63%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(initializer_op)\n",
    "    print(\"Training for \", epochs, \" epochs.\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        avg_cost= 0.0\n",
    "        avg_accuracy_pct=0.0\n",
    "        \n",
    "        n_batches = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(n_batches):\n",
    "            \n",
    "            # reassurance \n",
    "            if i%display_progress == 0:\n",
    "                print(\"Step \", i+1, \" of \", n_batches, \" in epoch \", epoch+1, \".\", sep='')\n",
    "                \n",
    "            batch_x, batch_y =  mnist.train.next_batch(batch_size)\n",
    "            _, batch_cost, batch_acc = session.run([optimizer, cost, accuracy_pct],\n",
    "                feed_dict={x:batch_x,y: batch_y})\n",
    "            avg_cost += batch_cost/n_batches\n",
    "            avg_accuracy_pct += batch_acc/n_batches\n",
    "        \n",
    "        # output logs at end of each epoch of training:\n",
    "        print(\"Epoch \", '%03d' % (epoch+1), \n",
    "              \": cost = \", '{:.3f}'.format(avg_cost), \n",
    "              \", accuracy = \", '{:.2f}'.format(avg_accuracy_pct), \"%\", \n",
    "              sep='')\n",
    "    \n",
    "    print(\"Training Complete. Testing Model.\\n\")\n",
    "                    \n",
    "    test_cost = cost.eval({x: mnist.test.images, y: mnist.test.labels})\n",
    "    test_accuracy_pct = accuracy_pct.eval({x: mnist.test.images, y: mnist.test.labels})  \n",
    "                    \n",
    "    print(\"Test Cost:\", '{:.3f}'.format(test_cost))\n",
    "    print(\"Test Accuracy: \", '{:.2f}'.format(test_accuracy_pct), \"%\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

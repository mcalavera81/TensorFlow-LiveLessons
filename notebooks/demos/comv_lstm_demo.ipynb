{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet LSTM in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use a *bidirectional* LSTM to classify IMDB movie reviews by their sentiment with a *Convolutional-Bidirectional LSTM Stack*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers.wrappers import Bidirectional # new! \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/convBiLSTM'\n",
    "\n",
    "# training:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 200 # doubled!\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "#Conv Layer\n",
    "n_conv=64\n",
    "k_conv=3\n",
    "mp_size = 4\n",
    "\n",
    "# LSTM layer architecture:\n",
    "n_lstm = 64 \n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # removed n_words_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(MaxPooling1D(mp_size))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 200, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 198, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 49, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 718,529\n",
      "Trainable params: 718,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM layer parameters double due to both reading directions\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 48s 2ms/step - loss: 0.4648 - acc: 0.7537 - val_loss: 0.3077 - val_acc: 0.8713\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.2407 - acc: 0.9062 - val_loss: 0.3100 - val_acc: 0.8697\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 43s 2ms/step - loss: 0.1804 - acc: 0.9320 - val_loss: 0.3300 - val_acc: 0.8640\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 44s 2ms/step - loss: 0.1381 - acc: 0.9500 - val_loss: 0.3725 - val_acc: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c979fef28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - we see 87.0% validation accuracy in epoch 2\n",
    "# - with this toy dataset, the complex interplay of words over long sentence segments, won't be learned much\n",
    "# - so our CNN picking up location-invariant segments of two to four words that predict review sentiment\n",
    "# - these are simpler and so easier to learn from the data\n",
    "# - CNN therefore outperforms on the IMDB data set\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.01.hdf5\") # zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c93420eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'94.50'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
